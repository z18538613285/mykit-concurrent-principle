package io.gushizhao.actualcase.lab02;

/**
 * @Author huzhichao
 * @Description TODO
 * @Date 2023/3/28 10:18
 *
 * 高并发架构相关概念
 * 什么是并发？
 * 并发是指并发的访问，也就是某个时间点，有多少个访问同时到来；
 * 并发数 = QPS*平均响应时间
 *
 * 高并发具体关心什么？
 * QPS： 每秒请求或查询的数量，在互联网领域，指每秒响应请求数；
 * 吞吐量： 单位时间内处理的请求量（通常由QPS与并发数决定）；
 * 响应时间： 从请求发出到收到响应花费的时间，例如一个系统处理一个HTTP请求需要100ms，这个100ms就是系统的响应时
 * 间；
 * PV： 综合浏览量，即页面浏览量或者点击量，一个访客在24小时内访问的页面数量；
 * UV： 独立访客 ，即一定时间范围内相同访客多次访问网站，只计算为一个独立的访客；
 * 带宽： 计算带宽大小需要关注两个指标，峰值流量和页面的平均大小 ；
 * 日网站带宽可以使用下面的公式来粗略计算：
 * 日网站带宽=pv/统计时间（换算到秒）*平均页面大小（单位kB）*8
 *峰值一般是平均值的倍数；
 * QPS不等于并发连接数，QPS是每秒HTTP请求数量，并发连接数是系统同时处理的请求数量；
 * 峰值每秒请求数（QPS） = (总PV数 * 80%) /（6小时秒数 * 20%）
 *
 * 压力测试： 测试能承受的最大并发，测试最大承受的QPS值。
 * 测试工具（ab）： 目标是URL，可以创建多个访问线程对同一个URL进行访问（Nginx）；
 * ab的使用： 模拟并发请求100次（100个人），总共请求5000次（每个人请求5000次）
 * ab -c 100 -n 5000 待测试网站（内存和网络不超过最高限度的75%）
 *
 *
 * QPS达到50： 一般的服务器就可以应付；
 * QPS达到100： 假设关系型数据库的每次请求在0.01秒完成（理想），假设单页面只有一个SQL查询，那么100QPS意味着1秒中
 * 完成100次请求，但此时我们不能保证数据库查询能完成100次；
 * 方案：数据库缓存层、数据库的负载均衡；
 * QPS达到800： 假设我们使用 百兆宽带，意味着网站出口的实际带宽是8M左右，假设每个页面是有10k，在这个并发的条件下，
 * 百兆带宽已经被吃完；
 * 方案：CDN加速、负载均衡
 * QPS达到1000： 假设使用Redis缓存数据库查询数据，每个页面对Redis请求远大于直接对DB的请求；
 * Redis的悲观并发数在5W左右，但有可能之前内网带宽已经被吃光，表现出不稳定；
 * 方案：静态HTML缓存
 *QPS达到2000： 文件系统访问锁都成为了灾难；
 * 方案：做业务分离，分布式存储；
 *
 * 高并发解决方案案例
 * 流量优化： 防盗链处理（把一些恶意的请求拒之门外）
 * 前端优化： 减少HTTP请求、添加异步请求、启用浏览器的缓存和文件压缩、CDN加速、建立独立的图片服务器；
 * 服务端优化： 页面静态化处理、并发处理、队列处理；
 * 数据库优化： 数据库的缓存、分库分表、分区操作、读写分离、负载均衡
 * Web服务器优化： 负载均衡
 *
 * 高并发下的经验公式
 * 通过QPS和PV计算部署服务器的台数
 * 单台服务器每天PV计算
 * 公式1：每天总PV = QPS * 3600 * 6
 * 公式2：每天总PV = QPS * 3600 * 8
 *
 * 服务器计算
 * 服务器数量 = ceil( 每天总PV / 单台服务器每天总PV )
 *
 * 峰值QPS和机器计算公式
 * 原理： 每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间
 * 公式： ( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS)
 * 机器： 峰值时间每秒QPS / 单台机器的QPS = 需要的机器。
 *
 *
 *
 * CAS 与 synchronized 的使用场景
 * 简单的来说 CAS 适用于写比较少的情况下（多读场景，冲突一般较少），synchronized 适用于写比较多的情况下（多写场景，
 * 冲突一般较多）
 *(1)对于资源竞争较少（线程冲突较轻）的情况，使用 synchronized 同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切
 * 换操作额外浪费消耗cpu 资源；而 CAS 基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以
 * 获得更高的性能。
 *(2)对于资源竞争严重（线程冲突严重）的情况， CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于
 * synchronized
 *
 * 补充： Java 并发编程这个领域中 synchronized 关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但
 * 是，在 JavaSE 1.6 之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化
 * 之后变得在某些情况下并不是那么重了。 synchronized 的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞， 竞争
 * 切换后继续竞争锁， 稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和 CAS 类似的性能；而线程
 * 冲突严重的情况下，性能远高于CAS。
 *
 *
 *
 *
 *
 *
 */
public class ConcurrentTest {
}
